==========
Design of energyweb -- The Energy Monitoring System for Harvey Mudd College
==========

Authors of Program:
------------------

    Chandler May, HMC Math '11 - cjmay4754@gmail.com

    Beryl Egerter, HMC CS '13 - beryl_egerter@hmc.edu
    Rai Feren, HMC CS '13 - rai_feren@hmc.edu

==========

Purpose:
------
    For monitoring the energy usage of the various buildings on Harvey
    Mudd College. This system creates a website on which users can
    view a graph that displays the readings from the energy
    monitors. Graphs can be either updating in real time but
    constrained time periods, or user specified static graphs.

==========
HOW TO USE
==========

How to use git:
----------
    Work is hosted on github. This allows for open source
    collaboration.

    Follow git's documentation for forking the project and installing
    git if necessary. The following will assume you already have a
    copy cloned to your computer.

    If a file has been added or changed, execute the following
    commands

        git add <FILENAME>
            Yes, use add EVEN when changing or deleting a file. This
            adds it to the list of things to be committed.
        git commit
            This will open up your default editor. Place a Subject
            line on the first line, then have a blank line, then
            whatever your update message is.
            This command seems to exist mostly to set the commit
            message.
        git push
            This command actually sends it to the git server.

    If a file has been changed on git, execute the following command
    
        git pull

How to Run:
---------
    All files are kept in /var/local/energyweb (energy's home directory)
    In order to access the database, use 
       psql energy
    while logged in as energy (sudo su - energy)   
      
        While in the database, can execute any SQL necessary. Any
        command that alters the structure of an existing table (IE:
        adding a column) must be done via SQL, not via syncdb.

    Once you're in...

    ./dev.sh init 
        Puts the server in a development environment. Will create a
        database with "development-friendly data"
    ./dev.sh start
        Starts all monitors
    ./dev.sh stop
        Stops all monitors
    ./dev.sh restart
        Restarts all monitors
    NOTE: Any functions that edit the database (namely init) must be
        run as energy.

    manage.py is for interacting with the Django framework. As you
    might notice by looking at dev.sh, dev.sh simply calls manage.py
    with various arguments.

    Useful Commands:
        python manage.py syncdb 
            Causes any changes in initial_data.json to be updated.
            If you edit models.py, this will add a new table, but it
            will not add any changes to already existing tables. You
            must do those yourself via SQL.
        python manage.py energy[faker/monitor] <number>
        <start/stop/restart> 
            Starts/Stops/Restarts either the faker or the associated
            monitor.

    When any changes have been made to the model or views layer, 
    must run /etc/init.d/apache2 restart
    This command is unnecessary for Templates layer (html/css/js)

   use the pg_dump function to dump the database into a file



==========
STRUCTURE
==========

    -----
    Overall:
    -----
        Diagram:

        PostgreSQL database <-- Python (energymon.py)
        \/
        Python (data.py) <--> Python (views.py) <-- Python (urls.py)
                                            \/
        Javascript and CSS (static) <--  HTML (templates)

        The system has three essential layers
            Model - the PostgreSQL database
            Views - the Django that handles the interaction between
                the Models and Template. Determines what data users
                can see.           
            Template - HTML, CSS, and Javascript for rendering the
                website. This is the only bit users directly interact with.
            
    -----
    Files:        
    -----

        -----
        Critical Files to Edit:
        -----

        settings.py - Contains various site wide settings, such as
                      activating debug tracebacks.

        initial_data.json - Contains data to populate database about
                the sensors and sensor groups. Add a new sensor/sensor
                group or modify an old one by editing this file and
                then running manage.py's syncdb command.

        graph/management/commands/

        graph/constants.py
        graph/views.py
        graph/data.py
        graph/urls.py
        graph/context_processors.py
 
            When a user inputs a URL, it is matched against a regular
            expression in urls.py. 
            These regular expressions pass arguments to functions in
            views.py.  
            These functions call functions in data.py to query the
            database. 
            Then views.py returns a context, which is paired with
            global contexts from context_processors.py to fill in html
            files in the templates folder.

        All html files in template/graph/
        All css files in static/css/
        All js files in static/js/page_specific/

    ---------------
    Data Structures: 
    ---------------

        Inside the Database, there are the following tables,

            SensorGroup - Details on Buildings
                name (IE: North)
                color (in hex)
                scope (determines whether Residential or Academic)

            Sensor
                name (IE: HVAC, usually empty string)
                ip
                sensor_group (whichever one it belongs to)
                three_phase (boolean, tells whether to ignore c or not)
                factor (Conversion rate from raw data to meaningful
                readings)
                port

            SensorReading - Raw Data, used only to calculate Averages
                sensor
                reading_time
                rindex
                {a,b,c}watthr (Summed when determining PowerAverages)
                {a,b,c}varhr
                {a,b,c}vahr
                {a,b,c}irms
                {a,b,c}vrms
                freq
                tempc

            PowerAverage - All data for graphing and tables come from
                            here 
                first_reading_time
                last_reading_time
                trunc_reading_time (Time used for graphing)
                sensor
                num_points
                watts
                average_type (must be one of the pre-specified types)

            SRProfile - Sensor Reading Profile, for mon_status page.
                sensor_reading
                power_average_inserts
                power_average_updates
                transaction_time

            Setting - Honestly not sure what this is used for
                name (32 characters)
                value_type (32 characters)
                value (Text)

            Signal - Contains the raw data readings
                name (32 characters)
                data (Text)

        ----

        Templates are broken up into two components:

                the base in templates/base.html

                the contents within the five files in the
                    templates/graph folders. 

        ----

        Views are managed in graph/views.py

    ---------------
    General Algorithms: 
    ---------------

        Averages are computed whenever a sensor reading is received,
        so that we don't need to repeatedly calculate them later.

        Whenever data is needed for a data table or a graph, the
        database is queried. The function used in most functions of
        data.py simply searches poweraverage for all data entries from
        a start_time to an end_time, then sorts them by time then
        sensor.
        This function will always return entries for all sensors,
        meaning the loops will sometimes go through several times more
        data than necessary. This also means several functions will
        either return more data than necessary or need to selectively
        return data.        

        The slowest running process is usually rendering the graph on
        a client's computer. The easiest solution is to simply use a
        more coarse resolution when plotting, thus less data points
        are necessary.

        Backing up data takes an extremely large amount of time. There
        does not appear to be an easy way to increase the speed of
        this process.

==========
LIMITATIONS
==========

    Inherent in System:
    ----
        Django requires a pre-Python 3.x installation.
        Devices send data every 10 seconds, thus all computation must
            be faster than 10 seconds.
        Devices can not accept more than one connection at a time.
        There is a large amount of data, such that backing it up takes
            30+ minutes and consumes the CPU for that time.

    Revisable:
    ----
        Data is currently only stored on the server itself without backups.
        System is unable to recognize when a sensor is down, causing
            delays in troubleshooting and thus more lost data.

==========
POSSIBLE IMPROVEMENTS
==========

    Watch the data coming in and figure out if a sensor has gone
        unusual/offline then send notification in some way.
    Automate data backup
